{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from file_parsers import parse_badges, parse_posts, parse_comments, parse_users,\\\n",
    "    parse_posthistory, parse_postlinks, parse_votes, parse_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('StackExchange') \\\n",
    "    .master('local[*]') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = '/home/piotr/big_data/archive.org/download/stackexchange/'\n",
    "#subject = 'meta.stackoverflow.com/'\n",
    "subject = 'gardening.stackexchange.com/'\n",
    "path = stack + subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "badges = parse_badges(sc, path + 'Badges.xml')\n",
    "posts = parse_posts(sc, path + 'Posts.xml')\n",
    "comments = parse_comments(sc, path + 'Comments.xml')\n",
    "users = parse_users(sc, path + 'Users.xml')\n",
    "posthistory = parse_posthistory(sc, path + 'PostHistory.xml')\n",
    "postlinks = parse_postlinks(sc, path + 'PostLinks.xml')\n",
    "votes = parse_votes(sc, path + 'Votes.xml')\n",
    "tags = parse_tags(sc, path + 'Tags.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: float (nullable = true)\n",
      " |-- PostTypeId: float (nullable = true)\n",
      " |-- ParentId: float (nullable = true)\n",
      " |-- AcceptedAnswerId: float (nullable = true)\n",
      " |-- CreationDate: string (nullable = true)\n",
      " |-- Score: float (nullable = true)\n",
      " |-- ViewCount: float (nullable = true)\n",
      " |-- Body: string (nullable = true)\n",
      " |-- OwnerUserId: float (nullable = true)\n",
      " |-- LastEditorUserId: float (nullable = true)\n",
      " |-- LastEditorDisplayName: string (nullable = true)\n",
      " |-- LastEditDate: string (nullable = true)\n",
      " |-- LastActivityDate: string (nullable = true)\n",
      " |-- CommunityOwnedDate: string (nullable = true)\n",
      " |-- ClosedDate: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Tags: string (nullable = true)\n",
      " |-- AnswerCount: float (nullable = true)\n",
      " |-- CommentCount: float (nullable = true)\n",
      " |-- FavoriteCount: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posts.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_filtered = posts.select(col('Id').cast('integer'), \\\n",
    "                             col('PostTypeId').cast('integer'), \\\n",
    "                             col('ParentId').cast('integer'), \\\n",
    "                             col('CreationDate').cast('timestamp'),\n",
    "                             col('AnswerCount').cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=1, PostTypeId=1, ParentId=None, CreationDate=datetime.datetime(2011, 6, 8, 18, 35, 50, 450000), AnswerCount=5),\n",
       " Row(Id=2, PostTypeId=1, ParentId=None, CreationDate=datetime.datetime(2011, 6, 8, 18, 37, 12, 493000), AnswerCount=2),\n",
       " Row(Id=3, PostTypeId=1, ParentId=None, CreationDate=datetime.datetime(2011, 6, 8, 18, 37, 45, 593000), AnswerCount=3)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_filtered.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|PostTypeId|count|\n",
      "+----------+-----+\n",
      "|         1|11008|\n",
      "|         5|  335|\n",
      "|         4|  335|\n",
      "|         7|    2|\n",
      "|         2|17451|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posts_filtered.groupBy('PostTypeId').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ile pytań bez odpowiedzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_filtered.filter(col('AnswerCount')==0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rozkład czasu pierwszej odpowiedzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = posts_filtered.filter(col('PostTypeId')==1)\n",
    "answers = posts_filtered.filter(col('PostTypeId')==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+--------------------+-----------+\n",
      "| Id|PostTypeId|ParentId|        CreationDate|AnswerCount|\n",
      "+---+----------+--------+--------------------+-----------+\n",
      "|  1|         1|    null|2011-06-08 18:35:...|          5|\n",
      "|  2|         1|    null|2011-06-08 18:37:...|          2|\n",
      "|  3|         1|    null|2011-06-08 18:37:...|          3|\n",
      "|  4|         1|    null|2011-06-08 18:37:...|          3|\n",
      "|  6|         1|    null|2011-06-08 18:39:...|          5|\n",
      "+---+----------+--------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+--------------------+-----------+\n",
      "| Id|PostTypeId|ParentId|        CreationDate|AnswerCount|\n",
      "+---+----------+--------+--------------------+-----------+\n",
      "|  5|         2|       1|2011-06-08 18:38:...|       null|\n",
      "|  9|         2|       1|2011-06-08 18:39:...|       null|\n",
      "| 11|         2|       4|2011-06-08 18:40:...|       null|\n",
      "| 12|         2|       1|2011-06-08 18:40:...|       null|\n",
      "| 14|         2|       2|2011-06-08 18:41:...|       null|\n",
      "+---+----------+--------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|ParentId|   min(CreationDate)|\n",
      "+--------+--------------------+\n",
      "|     148|2011-06-08 23:50:...|\n",
      "|     463|2011-06-13 23:48:...|\n",
      "|    1088|2011-07-03 13:31:...|\n",
      "|    1342|2011-07-21 05:30:...|\n",
      "|    1591|2011-08-05 23:49:...|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "first_answers = answers.groupBy('ParentId').agg(F.min(answers.CreationDate))\n",
    "first_answers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cos aliasami\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "df_as1 = questions.alias(\"questions\")\n",
    "df_as2 = first_answers.alias(\"first_answers\")\n",
    "joined = df_as1.join(df_as2, col(\"questions.Id\") == col(\"first_answers.ParentId\"), 'inner')\n",
    "questions_time = joined.select(col('Id'), col('CreationDate'), col('min(CreationDate)'))\n",
    "diff = questions_time.withColumn('diff', (unix_timestamp(col('min(CreationDate)'))-unix_timestamp(col('CreationDate')))/60)\n",
    "first_answer_time = diff.select(col('Id'), col('diff'))\n",
    "first_answer_time_pandas = first_answer_time.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688     0.000000\n",
       "1576    0.000000\n",
       "1872    0.000000\n",
       "2240    0.000000\n",
       "3801    0.383333\n",
       "3860    0.000000\n",
       "4700    0.000000\n",
       "4897    0.450000\n",
       "5152    0.000000\n",
       "5257    0.000000\n",
       "5399    0.000000\n",
       "5434    0.000000\n",
       "5672    0.000000\n",
       "6224    0.000000\n",
       "6326    0.000000\n",
       "6429    0.016667\n",
       "6564    0.000000\n",
       "6764    0.000000\n",
       "7017    0.000000\n",
       "7542    0.000000\n",
       "7807    0.000000\n",
       "8073    0.000000\n",
       "8107    0.000000\n",
       "8169    0.000000\n",
       "9482    0.000000\n",
       "9645    0.000000\n",
       "9953    0.000000\n",
       "Name: diff, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_answer_time_pandas[first_answer_time_pandas['diff']<1]['diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f76ca7db780>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#rozklad czasu od pytania do pierwszej odpowiedzi (ograniczony do pierwszej doby)\n",
    "sns.boxplot(first_answer_time_pandas[first_answer_time_pandas['diff']<60*24]['diff'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Detected implicit cartesian product for INNER join between logical plans\\nProject [cast(Id#6 as int) AS Id#138, cast(PostTypeId#7 as int) AS PostTypeId#139, cast(ParentId#8 as int) AS ParentId#140, cast(CreationDate#10 as timestamp) AS CreationDate#142, cast(AnswerCount#23 as int) AS AnswerCount#141]\\n+- Filter (((isnotnull(PostTypeId#7) && isnotnull(Id#6)) && isnotnull(ParentId#8)) && ((cast(PostTypeId#7 as int) = 1) && (cast(Id#6 as int) = cast(ParentId#8 as int))))\\n   +- LogicalRDD [Id#6, PostTypeId#7, ParentId#8, AcceptedAnswerId#9, CreationDate#10, Score#11, ViewCount#12, Body#13, OwnerUserId#14, LastEditorUserId#15, LastEditorDisplayName#16, LastEditDate#17, LastActivityDate#18, CommunityOwnedDate#19, ClosedDate#20, Title#21, Tags#22, AnswerCount#23, CommentCount#24, FavoriteCount#25], false\\nand\\nAggregate [ParentId#379], [ParentId#379, min(CreationDate#380) AS min(CreationDate)#214]\\n+- Project [cast(ParentId#8 as int) AS ParentId#379, cast(CreationDate#10 as timestamp) AS CreationDate#380]\\n   +- Filter (isnotnull(PostTypeId#7) && (cast(PostTypeId#7 as int) = 2))\\n      +- LogicalRDD [Id#6, PostTypeId#7, ParentId#8, AcceptedAnswerId#9, CreationDate#10, Score#11, ViewCount#12, Body#13, OwnerUserId#14, LastEditorUserId#15, LastEditorDisplayName#16, LastEditDate#17, LastActivityDate#18, CommunityOwnedDate#19, ClosedDate#20, Title#21, Tags#22, AnswerCount#23, CommentCount#24, FavoriteCount#25], false\\nJoin condition is missing or trivial.\\nEither: use the CROSS JOIN syntax to allow cartesian products between these\\nrelations, or: enable implicit cartesian products by setting the configuration\\nvariable spark.sql.crossJoin.enabled=true;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o756.showString.\n: org.apache.spark.sql.AnalysisException: Detected implicit cartesian product for INNER join between logical plans\nProject [cast(Id#6 as int) AS Id#138, cast(PostTypeId#7 as int) AS PostTypeId#139, cast(ParentId#8 as int) AS ParentId#140, cast(CreationDate#10 as timestamp) AS CreationDate#142, cast(AnswerCount#23 as int) AS AnswerCount#141]\n+- Filter (((isnotnull(PostTypeId#7) && isnotnull(Id#6)) && isnotnull(ParentId#8)) && ((cast(PostTypeId#7 as int) = 1) && (cast(Id#6 as int) = cast(ParentId#8 as int))))\n   +- LogicalRDD [Id#6, PostTypeId#7, ParentId#8, AcceptedAnswerId#9, CreationDate#10, Score#11, ViewCount#12, Body#13, OwnerUserId#14, LastEditorUserId#15, LastEditorDisplayName#16, LastEditDate#17, LastActivityDate#18, CommunityOwnedDate#19, ClosedDate#20, Title#21, Tags#22, AnswerCount#23, CommentCount#24, FavoriteCount#25], false\nand\nAggregate [ParentId#379], [ParentId#379, min(CreationDate#380) AS min(CreationDate)#214]\n+- Project [cast(ParentId#8 as int) AS ParentId#379, cast(CreationDate#10 as timestamp) AS CreationDate#380]\n   +- Filter (isnotnull(PostTypeId#7) && (cast(PostTypeId#7 as int) = 2))\n      +- LogicalRDD [Id#6, PostTypeId#7, ParentId#8, AcceptedAnswerId#9, CreationDate#10, Score#11, ViewCount#12, Body#13, OwnerUserId#14, LastEditorUserId#15, LastEditorDisplayName#16, LastEditDate#17, LastActivityDate#18, CommunityOwnedDate#19, ClosedDate#20, Title#21, Tags#22, AnswerCount#23, CommentCount#24, FavoriteCount#25], false\nJoin condition is missing or trivial.\nEither: use the CROSS JOIN syntax to allow cartesian products between these\nrelations, or: enable implicit cartesian products by setting the configuration\nvariable spark.sql.crossJoin.enabled=true;\n\tat org.apache.spark.sql.catalyst.optimizer.CheckCartesianProducts$$anonfun$apply$22.applyOrElse(Optimizer.scala:1295)\n\tat org.apache.spark.sql.catalyst.optimizer.CheckCartesianProducts$$anonfun$apply$22.applyOrElse(Optimizer.scala:1292)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:256)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:256)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:255)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.transformDown(AnalysisHelper.scala:149)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:261)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:261)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:261)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.transformDown(AnalysisHelper.scala:149)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:261)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:261)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:261)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.transformDown(AnalysisHelper.scala:149)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:261)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:261)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:324)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:261)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.transformDown(AnalysisHelper.scala:149)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:245)\n\tat org.apache.spark.sql.catalyst.optimizer.CheckCartesianProducts$.apply(Optimizer.scala:1292)\n\tat org.apache.spark.sql.catalyst.optimizer.CheckCartesianProducts$.apply(Optimizer.scala:1274)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:57)\n\tat scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:66)\n\tat scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:35)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.execution.QueryExecution.optimizedPlan$lzycompute(QueryExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution.optimizedPlan(QueryExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:72)\n\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:68)\n\tat org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:77)\n\tat org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3359)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4acdb43b5329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_as1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_as2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_as1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf_as2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ParentId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \"\"\"\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Detected implicit cartesian product for INNER join between logical plans\\nProject [cast(Id#6 as int) AS Id#138, cast(PostTypeId#7 as int) AS PostTypeId#139, cast(ParentId#8 as int) AS ParentId#140, cast(CreationDate#10 as timestamp) AS CreationDate#142, cast(AnswerCount#23 as int) AS AnswerCount#141]\\n+- Filter (((isnotnull(PostTypeId#7) && isnotnull(Id#6)) && isnotnull(ParentId#8)) && ((cast(PostTypeId#7 as int) = 1) && (cast(Id#6 as int) = cast(ParentId#8 as int))))\\n   +- LogicalRDD [Id#6, PostTypeId#7, ParentId#8, AcceptedAnswerId#9, CreationDate#10, Score#11, ViewCount#12, Body#13, OwnerUserId#14, LastEditorUserId#15, LastEditorDisplayName#16, LastEditDate#17, LastActivityDate#18, CommunityOwnedDate#19, ClosedDate#20, Title#21, Tags#22, AnswerCount#23, CommentCount#24, FavoriteCount#25], false\\nand\\nAggregate [ParentId#379], [ParentId#379, min(CreationDate#380) AS min(CreationDate)#214]\\n+- Project [cast(ParentId#8 as int) AS ParentId#379, cast(CreationDate#10 as timestamp) AS CreationDate#380]\\n   +- Filter (isnotnull(PostTypeId#7) && (cast(PostTypeId#7 as int) = 2))\\n      +- LogicalRDD [Id#6, PostTypeId#7, ParentId#8, AcceptedAnswerId#9, CreationDate#10, Score#11, ViewCount#12, Body#13, OwnerUserId#14, LastEditorUserId#15, LastEditorDisplayName#16, LastEditDate#17, LastActivityDate#18, CommunityOwnedDate#19, ClosedDate#20, Title#21, Tags#22, AnswerCount#23, CommentCount#24, FavoriteCount#25], false\\nJoin condition is missing or trivial.\\nEither: use the CROSS JOIN syntax to allow cartesian products between these\\nrelations, or: enable implicit cartesian products by setting the configuration\\nvariable spark.sql.crossJoin.enabled=true;'"
     ]
    }
   ],
   "source": [
    "#df_as1.join(df_as2, df_as1['Id'] == df_as2['ParentId'], 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ParentId: int, min(CreationDate): timestamp]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_as2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Badges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.sort('Count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_time = posts.select([col('CreationDate').cast('date'), col('AnswerCount'), col('CommentCount')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_time.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import month, year\n",
    "bitcoin_popularity = posts_time.groupBy(year('CreationDate')).count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_popularity.cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
